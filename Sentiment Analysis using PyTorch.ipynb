{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53d7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#import contractions\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import gensim.downloader as api\n",
    "import gensim.models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2213aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056d61fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu124'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2f701",
   "metadata": {},
   "source": [
    "##### VERSIONS OF OTHER LIBRARIES USED\n",
    "\n",
    "scikit-image : 0.19.2 <br>\n",
    "numpy : 1.21.5 <br>\n",
    "pandas : 1.4.2 <br>\n",
    "contractions : 0.1.73 <br>\n",
    "gensim : 4.1.2 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3cd26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c125134d",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0fc2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data: https://www.kaggle.com/datasets/magodobolo/amazon-dataset-reviews-beauty\n",
    "import os\n",
    "os.chdir('/home/faculty10/tuanle/Teaching/s25-nlp/week6/')\n",
    "df = pd.read_csv('amazon_reviews_beauty.csv', header=0, sep=',', quotechar='\"', on_bad_lines='skip', dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802cecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Such a lovely scent but not overpowering.</td>\n",
       "      <td>This spray is really nice. It smells really go...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>1588687728923</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Works great but smells a little weird.</td>\n",
       "      <td>This product does what I need it to do, I just...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>1588615855070</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes!</td>\n",
       "      <td>Smells good, feels great!</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07PNNCSP9</td>\n",
       "      <td>B097R46CSY</td>\n",
       "      <td>AE74DYR3QUGVPZJ3P7RFWBGIX7XQ</td>\n",
       "      <td>1589665266052</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Synthetic feeling</td>\n",
       "      <td>Felt synthetic</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09JS339BZ</td>\n",
       "      <td>B09JS339BZ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>1643393630220</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>Love it</td>\n",
       "      <td>[]</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>1609322563534</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701523</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Conditioner is great  shampoo not as I expected</td>\n",
       "      <td>[]</td>\n",
       "      <td>B006YUIWKA</td>\n",
       "      <td>B006YUIWKA</td>\n",
       "      <td>AFIXGFVEGLMOTMBTJL7H3VSIETDQ</td>\n",
       "      <td>1478227021000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701524</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Pretty</td>\n",
       "      <td>Did not work! Used the whole bottle and my hai...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B006YUIWKA</td>\n",
       "      <td>B006YUIWKA</td>\n",
       "      <td>AFV7YZFOJF564EZGET5LG45K4QEA</td>\n",
       "      <td>1480908730000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701525</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great sunless tanner</td>\n",
       "      <td>Product as expected. Shipping was on time.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B06ZZV9MZT</td>\n",
       "      <td>B06ZZV9MZT</td>\n",
       "      <td>AHYDCWDMMVMLBX7FY7M7JKADKRDQ</td>\n",
       "      <td>1590547974067</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701526</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The Crown on top is a Ring!!!</td>\n",
       "      <td>Not only is it a delicious fragrance, but also...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B000HB6VLE</td>\n",
       "      <td>B000HB6VLE</td>\n",
       "      <td>AF6ZIAEN7TQ2WY5ZL77F6JDPV7XQ</td>\n",
       "      <td>1184798209000</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701527</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Good Shampoo/Conditioner</td>\n",
       "      <td>The conditioner doesn't really make your hair ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B0093MXHFG</td>\n",
       "      <td>B0093MXHFG</td>\n",
       "      <td>AGIYQU6RK6TBKBCMWKVPBPBMMJNA</td>\n",
       "      <td>1366944486000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>701528 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                      title  \\\n",
       "0         5.0  Such a lovely scent but not overpowering.   \n",
       "1         4.0     Works great but smells a little weird.   \n",
       "2         5.0                                       Yes!   \n",
       "3         1.0                          Synthetic feeling   \n",
       "4         5.0                                         A+   \n",
       "...       ...                                        ...   \n",
       "701523    4.0                                 Four Stars   \n",
       "701524    1.0                                     Pretty   \n",
       "701525    5.0                       Great sunless tanner   \n",
       "701526    5.0              The Crown on top is a Ring!!!   \n",
       "701527    4.0                   Good Shampoo/Conditioner   \n",
       "\n",
       "                                                     text images        asin  \\\n",
       "0       This spray is really nice. It smells really go...     []  B00YQ6X8EO   \n",
       "1       This product does what I need it to do, I just...     []  B081TJ8YS3   \n",
       "2                               Smells good, feels great!     []  B07PNNCSP9   \n",
       "3                                          Felt synthetic     []  B09JS339BZ   \n",
       "4                                                 Love it     []  B08BZ63GMJ   \n",
       "...                                                   ...    ...         ...   \n",
       "701523    Conditioner is great  shampoo not as I expected     []  B006YUIWKA   \n",
       "701524  Did not work! Used the whole bottle and my hai...     []  B006YUIWKA   \n",
       "701525         Product as expected. Shipping was on time.     []  B06ZZV9MZT   \n",
       "701526  Not only is it a delicious fragrance, but also...     []  B000HB6VLE   \n",
       "701527  The conditioner doesn't really make your hair ...     []  B0093MXHFG   \n",
       "\n",
       "       parent_asin                       user_id      timestamp helpful_vote  \\\n",
       "0       B00YQ6X8EO  AGKHLEW2SOWHNMFQIJGBECAF7INQ  1588687728923            0   \n",
       "1       B081TJ8YS3  AGKHLEW2SOWHNMFQIJGBECAF7INQ  1588615855070            1   \n",
       "2       B097R46CSY  AE74DYR3QUGVPZJ3P7RFWBGIX7XQ  1589665266052            2   \n",
       "3       B09JS339BZ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  1643393630220            0   \n",
       "4       B08BZ63GMJ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  1609322563534            0   \n",
       "...            ...                           ...            ...          ...   \n",
       "701523  B006YUIWKA  AFIXGFVEGLMOTMBTJL7H3VSIETDQ  1478227021000            0   \n",
       "701524  B006YUIWKA  AFV7YZFOJF564EZGET5LG45K4QEA  1480908730000            0   \n",
       "701525  B06ZZV9MZT  AHYDCWDMMVMLBX7FY7M7JKADKRDQ  1590547974067            0   \n",
       "701526  B000HB6VLE  AF6ZIAEN7TQ2WY5ZL77F6JDPV7XQ  1184798209000            4   \n",
       "701527  B0093MXHFG  AGIYQU6RK6TBKBCMWKVPBPBMMJNA  1366944486000            1   \n",
       "\n",
       "       verified_purchase  \n",
       "0                   True  \n",
       "1                   True  \n",
       "2                   True  \n",
       "3                   True  \n",
       "4                   True  \n",
       "...                  ...  \n",
       "701523              True  \n",
       "701524             False  \n",
       "701525              True  \n",
       "701526             False  \n",
       "701527              True  \n",
       "\n",
       "[701528 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d0c8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This spray is really nice. It smells really go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This product does what I need it to do, I just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Smells good, feels great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Felt synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701523</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Conditioner is great  shampoo not as I expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701524</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Did not work! Used the whole bottle and my hai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701525</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Product as expected. Shipping was on time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701526</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Not only is it a delicious fragrance, but also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701527</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The conditioner doesn't really make your hair ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>701528 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                               text\n",
       "0         5.0  This spray is really nice. It smells really go...\n",
       "1         4.0  This product does what I need it to do, I just...\n",
       "2         5.0                          Smells good, feels great!\n",
       "3         1.0                                     Felt synthetic\n",
       "4         5.0                                            Love it\n",
       "...       ...                                                ...\n",
       "701523    4.0    Conditioner is great  shampoo not as I expected\n",
       "701524    1.0  Did not work! Used the whole bottle and my hai...\n",
       "701525    5.0         Product as expected. Shipping was on time.\n",
       "701526    5.0  Not only is it a delicious fragrance, but also...\n",
       "701527    4.0  The conditioner doesn't really make your hair ...\n",
       "\n",
       "[701528 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df.iloc[:, 0], df.iloc[:, 2]], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5df9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['rating','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b903e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None \n",
    "def labelClass(rating):\n",
    "    if rating == \"1.0\" or rating == \"2.0\":\n",
    "          return 1\n",
    "    if rating == \"3.0\" :\n",
    "          return 2\n",
    "    if rating == \"4.0\" or rating  == \"5.0\":\n",
    "          return 3\n",
    "df['class'] = df['rating'].map(labelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505ecd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A BALANCED DATASET OF 60K REVIEWS, LIKE HW1\n",
    "class1 = df.loc[df['class'] == 1].sample(n=20000, random_state=1)\n",
    "class2 = df.loc[df['class'] == 2].sample(n=20000, random_state=1)\n",
    "class3 = df.loc[df['class'] == 3].sample(n=20000, random_state=1)\n",
    "df = pd.concat([class1, class2, class3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95aa32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "/tmp/ipykernel_37037/1946699171.py:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  df['text'] = df['text'].apply(lambda x: re.sub(re.compile('http\\S+|https\\S+'), \"\", x))  # REMOVE ALL URLs\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].str.lower()  # CONVERT ALL REVEIWS TO LOWERCASE\n",
    "df['text'] = df['text'].astype(str)  \n",
    "df['text'] = df['text'].apply(lambda x: re.sub(re.compile('http\\S+|https\\S+'), \"\", x))  # REMOVE ALL URLs \n",
    "df['text'] = df['text'].apply(lambda x: re.sub(re.compile('<.*?>'), \"\", x))   # REMOVE ALL HTML TAGS\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(re.compile(\"[^A-Za-z]\"),\" \", x))  # REMOVE ALL NON-ALPHABETICAL CHARACTERS\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(re.compile(' +'),' ', x))  # REMOVES EXTRA SPACES IN REVIEWS\n",
    "df['text'] = df['text'].apply(lambda x: contractions.fix(x))  # PERFORM CONTRACTIONS ON REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545cd2b",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd61a02",
   "metadata": {},
   "source": [
    "#### PART A (PRETRAINED WORD2VEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f6bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7611f1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK SIMILARITY BETWEEN THE FOLLOWING 2 WORDS\n",
    "word_2_vec.similarity(\"gorgeous\", \"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ea745fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66321707"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK SIMILARITY BETWEEN THE FOLLOWING 2 WORDS\n",
    "word_2_vec.similarity(\"happy\", \"pleased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b8f80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lady', 0.5354641079902649)\n",
      "('person', 0.529635488986969)\n",
      "('Woman', 0.513024628162384)\n",
      "('men', 0.4956325590610504)\n",
      "('policewoman', 0.4909151792526245)\n"
     ]
    }
   ],
   "source": [
    "neighbors = word_2_vec.most_similar(positive=['man', 'woman'], negative=['boy'], topn=5)\n",
    "for n in neighbors:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c23a3",
   "metadata": {},
   "source": [
    "#### PART B (WORD2VEC TRAINED ON OUR DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd98eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THE REVIEWS INTO INDIVIDUAL WORDS\n",
    "sentences = []\n",
    "for i in range(len(df['text'])):\n",
    "    sentences.append(df['text'].values[i].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a36c4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=300, min_count=9, window=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b2f154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857682"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK SIMILARITY BETWEEN THE FOLLOWING 2 WORDS\n",
    "model.wv.similarity(\"gorgeous\", \"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6c5436f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91375065"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK SIMILARITY BETWEEN THE FOLLOWING 2 WORDS\n",
    "model.wv.similarity(\"happy\", \"pleased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7311b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lady', 0.5354641079902649)\n",
      "('person', 0.529635488986969)\n",
      "('Woman', 0.513024628162384)\n",
      "('men', 0.4956325590610504)\n",
      "('policewoman', 0.4909151792526245)\n"
     ]
    }
   ],
   "source": [
    "neighbors = word_2_vec.most_similar(positive=['man', 'woman'], negative=['boy'], topn=5)\n",
    "for n in neighbors:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf585689",
   "metadata": {},
   "source": [
    "# Simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71d1ce",
   "metadata": {},
   "source": [
    "## Using TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d163c088",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating X data and y labels\n",
    "X = df['text']\n",
    "y = df['class']\n",
    "    \n",
    "# Applying TFIDF feature extraction on X\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7737d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28271) (12000, 28271) (48000,) (12000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=10)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8888b",
   "metadata": {},
   "source": [
    "### Perceptron using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a80d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT A SINGLE PERCEPTRON MODEL ON OUR DATASET\n",
    "model1 = Perceptron(tol=1e-3, random_state=100)\n",
    "model1.fit(X_train, y_train)\n",
    "y_predict = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfda7f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.67      0.65      3749\n",
      "           2       0.56      0.54      0.55      4118\n",
      "           3       0.74      0.73      0.73      4133\n",
      "\n",
      "    accuracy                           0.64     12000\n",
      "   macro avg       0.64      0.65      0.64     12000\n",
      "weighted avg       0.64      0.64      0.64     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report1 = classification_report(y_predict, y_test, output_dict=True)\n",
    "print(classification_report(y_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4d02558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\tPrecision\t\tRecall\t\t\tF1-score\n",
      "\n",
      "1     \t0.6329050138573948,\t0.6700453454254468,\t0.6509458408914226\n",
      "2     \t0.558705469141997,\t0.5407965031568722,\t0.5496051332675223\n",
      "3     \t0.7414091470951792,\t0.7256230341156545,\t0.7334311567620445\n",
      "average\t0.6443398766981904,\t0.6454882942326577,\t0.6446607103069965 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Class\\tPrecision\\t\\tRecall\\t\\t\\tF1-score\\n')\n",
    "print('1     '+\"\\t\"+ str(report1['1']['precision'])+\",\\t\"+str(report1['1']['recall'])+\",\\t\"+ str(report1['1']['f1-score']))\n",
    "print('2     '+\"\\t\"+ str(report1['2']['precision'])+\",\\t\"+str(report1['2']['recall'])+\",\\t\"+ str(report1['2']['f1-score']))\n",
    "print('3     '+\"\\t\"+ str(report1['3']['precision'])+\",\\t\"+str(report1['3']['recall'])+\",\\t\"+ str(report1['3']['f1-score']))\n",
    "print('average' +\"\\t\"+str((report1['1']['precision']+report1['2']['precision']+report1['3']['precision'])/3)+\",\\t\"+str((report1['1']['recall']+report1['2']['recall']+report1['3']['recall'])/3)+\",\\t\"+str((report1['1']['f1-score']+report1['2']['f1-score']+report1['3']['f1-score'])/3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418531ae",
   "metadata": {},
   "source": [
    "### SVM using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed5fb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT A SVM MODEL ON OUR DATASET\n",
    "model2 = LinearSVC(random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "y_predict = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e93bdbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71      4023\n",
      "           2       0.60      0.60      0.60      3975\n",
      "           3       0.79      0.80      0.79      4002\n",
      "\n",
      "    accuracy                           0.70     12000\n",
      "   macro avg       0.70      0.70      0.70     12000\n",
      "weighted avg       0.70      0.70      0.70     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report2 = classification_report(y_predict, y_test, output_dict=True)\n",
    "print(classification_report(y_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3645d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\tPrecision\t\tRecall\t\t\tF1-score\n",
      "\n",
      "1     \t0.7102544721592341,\t0.7007208550832712,\t0.7054554554554554\n",
      "2     \t0.5995985950827898,\t0.6012578616352201,\t0.6004270820248713\n",
      "3     \t0.7888751545117428,\t0.7973513243378311,\t0.7930905927674909\n",
      "average\t0.6995760739179223,\t0.6997766803521075,\t0.6996577100826059 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Class\\tPrecision\\t\\tRecall\\t\\t\\tF1-score\\n')\n",
    "print('1     '+\"\\t\"+ str(report2['1']['precision'])+\",\\t\"+str(report2['1']['recall'])+\",\\t\"+ str(report2['1']['f1-score']))\n",
    "print('2     '+\"\\t\"+ str(report2['2']['precision'])+\",\\t\"+str(report2['2']['recall'])+\",\\t\"+ str(report2['2']['f1-score']))\n",
    "print('3     '+\"\\t\"+ str(report2['3']['precision'])+\",\\t\"+str(report2['3']['recall'])+\",\\t\"+ str(report2['3']['f1-score']))\n",
    "print('average' +\"\\t\"+str((report2['1']['precision']+report2['2']['precision']+report2['3']['precision'])/3)+\",\\t\"+str((report2['1']['recall']+report2['2']['recall']+report2['3']['recall'])/3)+\",\\t\"+str((report2['1']['f1-score']+report2['2']['f1-score']+report2['3']['f1-score'])/3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cecd195",
   "metadata": {},
   "source": [
    "## Word2Vec for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1f7b7",
   "metadata": {},
   "source": [
    "### Perceptron using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "081e5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "sent = []\n",
    "\n",
    "for i in range(len(df['text'])):\n",
    "    split_sent = df['text'].values[i].split(' ')\n",
    "    for word in split_sent:\n",
    "        try:\n",
    "            sent.append(word_2_vec[word])\n",
    "        except:\n",
    "            sent.append(np.zeros(300))\n",
    "    sent = np.array(sent)\n",
    "    sent = np.mean(sent, axis=0)\n",
    "    data.append(sent)\n",
    "    sent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9bb164b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 300) (12000, 300) (48000,) (12000,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data_label = df['class'].values\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data, data_label, test_size = 0.2, random_state=10)\n",
    "print(X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0a2d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT A SINGLE PERCEPTRON MODEL ON OUR DATASET\n",
    "model3 = Perceptron(tol=1e-3, random_state=10)\n",
    "model3.fit(X_train1, y_train1)\n",
    "y_predict = model3.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf9e1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.56      0.63      5019\n",
      "           2       0.58      0.50      0.54      4611\n",
      "           3       0.50      0.86      0.64      2370\n",
      "\n",
      "    accuracy                           0.60     12000\n",
      "   macro avg       0.60      0.64      0.60     12000\n",
      "weighted avg       0.62      0.60      0.59     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report3 = classification_report(y_predict, y_test1, output_dict=True)\n",
    "print(classification_report(y_predict,y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a84757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\tPrecision\t\tRecall\t\t\tF1-score\n",
      "\n",
      "1     \t0.7105064247921391,\t0.5618649133293485,\t0.6275033377837116\n",
      "2     \t0.579528349222278,\t0.5009759271307742,\t0.5373967663138304\n",
      "3     \t0.5043263288009888,\t0.8607594936708861,\t0.6360093530787218\n",
      "average\t0.5981203676051353,\t0.6412001113770031,\t0.600303152392088 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Class\\tPrecision\\t\\tRecall\\t\\t\\tF1-score\\n')\n",
    "print('1     '+\"\\t\"+ str(report3['1']['precision'])+\",\\t\"+str(report3['1']['recall'])+\",\\t\"+ str(report3['1']['f1-score']))\n",
    "print('2     '+\"\\t\"+ str(report3['2']['precision'])+\",\\t\"+str(report3['2']['recall'])+\",\\t\"+ str(report3['2']['f1-score']))\n",
    "print('3     '+\"\\t\"+ str(report3['3']['precision'])+\",\\t\"+str(report3['3']['recall'])+\",\\t\"+ str(report3['3']['f1-score']))\n",
    "print('average' +\"\\t\"+str((report3['1']['precision']+report3['2']['precision']+report3['3']['precision'])/3)+\",\\t\"+str((report3['1']['recall']+report3['2']['recall']+report3['3']['recall'])/3)+\",\\t\"+str((report3['1']['f1-score']+report3['2']['f1-score']+report3['3']['f1-score'])/3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097a6fb",
   "metadata": {},
   "source": [
    "### SVM using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d85ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT A SVM MODEL ON OUR DATASET\n",
    "model4 = LinearSVC(random_state=100)\n",
    "model4.fit(X_train1, y_train1)\n",
    "y_predict = model4.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a9a3a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.67      0.68      4094\n",
      "           2       0.57      0.58      0.57      3920\n",
      "           3       0.75      0.76      0.75      3986\n",
      "\n",
      "    accuracy                           0.67     12000\n",
      "   macro avg       0.67      0.67      0.67     12000\n",
      "weighted avg       0.67      0.67      0.67     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report4 = classification_report(y_predict, y_test1, output_dict=True)\n",
    "print(classification_report(y_predict,y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14f4c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\tPrecision\t\tRecall\t\t\tF1-score\n",
      "\n",
      "1     \t0.690854119425548,\t0.6697606253053249,\t0.6801438670470048\n",
      "2     \t0.5669844455594582,\t0.576530612244898,\t0.5717176827725778\n",
      "3     \t0.7456118665018542,\t0.7566482689412946,\t0.751089528078695\n",
      "average\t0.6678168104956201,\t0.6676465021638393,\t0.6676503592994258 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Class\\tPrecision\\t\\tRecall\\t\\t\\tF1-score\\n')\n",
    "print('1     '+\"\\t\"+ str(report4['1']['precision'])+\",\\t\"+str(report4['1']['recall'])+\",\\t\"+ str(report4['1']['f1-score']))\n",
    "print('2     '+\"\\t\"+ str(report4['2']['precision'])+\",\\t\"+str(report4['2']['recall'])+\",\\t\"+ str(report4['2']['f1-score']))\n",
    "print('3     '+\"\\t\"+ str(report4['3']['precision'])+\",\\t\"+str(report4['3']['recall'])+\",\\t\"+ str(report4['3']['f1-score']))\n",
    "print('average' +\"\\t\"+str((report4['1']['precision']+report4['2']['precision']+report4['3']['precision'])/3)+\",\\t\"+str((report4['1']['recall']+report4['2']['recall']+report4['3']['recall'])/3)+\",\\t\"+str((report4['1']['f1-score']+report4['2']['f1-score']+report4['3']['f1-score'])/3), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60da4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR PERCEPTRON -\n",
      "Test accuracy when using TF-IDF: 64.48333333333333 %\n",
      "Test accuracy when using Word2Vec: 59.75 %\n"
     ]
    }
   ],
   "source": [
    "pred = model1.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred) * 100\n",
    "pred1 = model3.predict(X_test1)\n",
    "acc1 = accuracy_score(y_test1, pred1) * 100\n",
    "print(\"FOR PERCEPTRON -\")\n",
    "print(\"Test accuracy when using TF-IDF:\", acc, \"%\")\n",
    "print(\"Test accuracy when using Word2Vec:\", acc1, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b0a87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR SVM -\n",
      "Test accuracy when using TF-IDF: 70.0 %\n",
      "Test accuracy when using Word2Vec: 66.81666666666666 %\n"
     ]
    }
   ],
   "source": [
    "pred3 = model2.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred3) * 100\n",
    "pred4 = model4.predict(X_test1)\n",
    "acc1 = accuracy_score(y_test1, pred4) * 100\n",
    "print(\"FOR SVM -\")\n",
    "print(\"Test accuracy when using TF-IDF:\", acc, \"%\")\n",
    "print(\"Test accuracy when using Word2Vec:\", acc1, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04574476",
   "metadata": {},
   "source": [
    "##### TF-IDF gives better results than Word2Vec for both Perceptron and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c67c5",
   "metadata": {},
   "source": [
    "# Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f357f",
   "metadata": {},
   "source": [
    "#### PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33c3277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE ONE-HOT ENCODINGS OF THE 3 RATINGS\n",
    "enc_data_label = np.zeros((len(data_label), 3))\n",
    "for i in range(len(data_label)):\n",
    "    if data_label[i] == 1:\n",
    "        enc_data_label[i] = [0, 0, 1]\n",
    "    elif data_label[i] == 2:\n",
    "        enc_data_label[i] = [0, 1, 0]\n",
    "    elif data_label[i] == 3:\n",
    "        enc_data_label[i] = [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdec7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 300) (12000, 300) (48000, 3) (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN-TEST-SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, enc_data_label, test_size = 0.2, random_state=10)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d39599c-e27c-4cbd-85a2-c08c705fe5d8",
   "metadata": {},
   "source": [
    "### Other activation functions used:\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#torch.nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e81bd98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNN IN PYTORCH\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(300, 100)   \n",
    "        self.dropout = nn.Dropout(0.2)   \n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(x)     # added dropout to reduce overfitting \n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "#         x = self.dropout(x)   # added dropout to reduce overfitting \n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b486ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USING GPU\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "317f1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_model = FNN().to(device)\n",
    "fnn_model = fnn_model.to(device)   # using '.to(device)' to move the model from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dde16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATASET CLASS FOR DATALOADERS\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data1, data2):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data1[idx]\n",
    "        y = self.data2[idx]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3fa78c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512  # BATCH SIZE FOR THIS MODEL\n",
    "train_dataset = Dataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_dataset = Dataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1435590",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(fnn_model.parameters(), lr = 0.001)  \n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55619c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.41718611480496454\n",
      "Train accuracy: 0.5781111480496454\n",
      "Train accuracy: 0.6403341090425532\n",
      "Train accuracy: 0.6577598625886525\n",
      "Train accuracy: 0.6649767287234043\n",
      "Train accuracy: 0.668287344858156\n",
      "Train accuracy: 0.6708984375\n",
      "Train accuracy: 0.6747977615248227\n",
      "Train accuracy: 0.6778105607269503\n",
      "Train accuracy: 0.6818622562056738\n",
      "Train accuracy: 0.6817583665780141\n",
      "Train accuracy: 0.6856438386524822\n",
      "Train accuracy: 0.6881441156914894\n",
      "Train accuracy: 0.6896886081560284\n",
      "Train accuracy: 0.6906720966312057\n",
      "Train accuracy: 0.6909145057624114\n",
      "Train accuracy: 0.6928745567375886\n",
      "Train accuracy: 0.6950216090425532\n",
      "Train accuracy: 0.6962198027482269\n",
      "Train accuracy: 0.6969608820921986\n",
      "Train accuracy: 0.6979097406914894\n",
      "Train accuracy: 0.6974734042553191\n",
      "Train accuracy: 0.6995442708333333\n",
      "Train accuracy: 0.7021830673758864\n",
      "Train accuracy: 0.7024462544326242\n",
      "Train accuracy: 0.7029657025709221\n",
      "Train accuracy: 0.7037829676418439\n",
      "Train accuracy: 0.705576795212766\n",
      "Train accuracy: 0.7059023160460992\n",
      "Train accuracy: 0.7073429188829787\n",
      "Final test accuracy: 0.6889299665178572\n"
     ]
    }
   ],
   "source": [
    "# TRAINING THE FNN MODEL\n",
    "history_train = []\n",
    "history_test = []\n",
    "train_dataloader_len = len(train_dataloader)\n",
    "test_dataloader_len = len(test_dataloader)\n",
    "train_len = X_train.shape[0]\n",
    "test_len = X_test.shape[0]\n",
    "\n",
    "for epoch in range(30):  # loops over the complete dataset multiple times (which is the nummber of epochs)\n",
    "    fnn_model.train()     \n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    train_accuracy = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):  # loops over complete training dataset once \n",
    "        \n",
    "        inputs, label = data\n",
    "        inputs = inputs.float()    # convert double values to float\n",
    "        inputs, label = inputs.to(device), label.to(device)   \n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        output = fnn_model(inputs)   # forward pass of model\n",
    "        output = output.to(device)\n",
    "        \n",
    "        loss1 = CEloss(output, label)     # loss calculation\n",
    "        loss1.backward()            # computes the gradient during the backward pass\n",
    "        model_optim.step()   # performs single optimization step\n",
    "\n",
    "        train_loss += loss1.item()   # adding accuracy values of all batches in an epoch\n",
    "        _, output = torch.max(output, 1)     # storing the index of maximum value in prediction to the variable 'output'\n",
    "        output = output.cpu().detach().numpy()     # loads the variable to cpu and converts it to a numpy array\n",
    "        label = label.cpu().detach().numpy()        \n",
    "        label = np.argmax(label, axis = 1)   # storing the index of maximum value in label to the variable 'label'\n",
    "        train_accuracy += accuracy_score(label, output)  # adding accuracy values of all batches in training dataset in an epoch\n",
    "    \n",
    "    train_loss = train_loss/train_dataloader_len\n",
    "    train_accuracy = train_accuracy/train_dataloader_len  # dividing accuracy by number of batches for training dataset\n",
    "    history_train.append((train_loss, train_accuracy))\n",
    "    \n",
    "    fnn_model.eval()     # model evaluation on test dataset\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():     # disables gradient calculation\n",
    "        for i, data in enumerate(test_dataloader, 0):    # loops over complete test dataset once\n",
    "            \n",
    "            inputs, label = data\n",
    "            inputs = inputs.float()\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "            pred = fnn_model(inputs)\n",
    "            pred = pred.to(device)\n",
    "            loss2 = CEloss(pred, label)\n",
    "\n",
    "            test_loss += loss2.item()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            label = label.cpu().detach().numpy()\n",
    "            label = np.argmax(label, axis = 1)    \n",
    "            test_accuracy += accuracy_score(label, pred)\n",
    "            \n",
    "        test_loss = test_loss/test_dataloader_len\n",
    "        test_accuracy = test_accuracy/test_dataloader_len\n",
    "        history_test.append((test_loss, test_accuracy))\n",
    "    \n",
    "#     print(\"Epoch:\", (epoch+1))\n",
    "#     print(\"Train Loss:\", train_loss, \"\\tTrain Accuracy:\", train_accuracy)\n",
    "#     print(\"Test Loss:\", test_loss, \"\\tTest Accuracy:\", test_accuracy)\n",
    "#     print(\"=======================================================================================\")\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "\n",
    "print(\"Final test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c43f4",
   "metadata": {},
   "source": [
    "#### PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7bca5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the first 10 Word2Vec vectors for each review\n",
    "concat_data = []\n",
    "sent = []\n",
    "for i in range(len(df['text'])):\n",
    "    split_sent = df['text'].values[i].split(' ')\n",
    "    for word in split_sent[:10]:\n",
    "        try:\n",
    "            sent.append(word_2_vec[word])\n",
    "        except:\n",
    "            \n",
    "            sent.append(list(np.zeros(300)))   \n",
    "    if len(sent) < 10:\n",
    "        sent = np.concatenate([sent,np.zeros((10-len(sent), 300))])\n",
    "    sent = np.array(sent)\n",
    "    sent = sent.flatten()\n",
    "    concat_data.append(sent)\n",
    "    sent = []\n",
    "concat_data = np.array(concat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbcc475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(3000, 100)\n",
    "        self.dropout = nn.Dropout(0.2)   \n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(x)     # added dropout to reduce overfitting \n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1e352f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_model1 = FNN1().to(device)\n",
    "fnn_model1 = fnn_model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af8b260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 3000) (12000, 3000) (48000, 3) (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(concat_data, enc_data_label, test_size = 0.2, random_state=10)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e63e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_dataset = Dataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_dataset = Dataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20709191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(fnn_model1.parameters(), lr = 0.001)\n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a5c59a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.546126994680851\n",
      "Train accuracy: 0.6177138741134751\n",
      "Train accuracy: 0.6393921764184397\n",
      "Train accuracy: 0.6540613918439716\n",
      "Train accuracy: 0.6709192154255319\n",
      "Train accuracy: 0.6910322473404256\n",
      "Train accuracy: 0.7137979277482269\n",
      "Train accuracy: 0.7340009973404256\n",
      "Train accuracy: 0.7574384973404256\n",
      "Train accuracy: 0.7788605385638298\n",
      "Final test accuracy: 0.6060965401785714\n"
     ]
    }
   ],
   "source": [
    "history_train = []\n",
    "history_test = []\n",
    "train_dataloader_len = len(train_dataloader)\n",
    "test_dataloader_len = len(test_dataloader)\n",
    "train_len = X_train.shape[0]\n",
    "test_len = X_test.shape[0]\n",
    "\n",
    "for epoch in range(10):  # loops over only 15 epochs because the model starts overfitting heavily after that\n",
    "    fnn_model1.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    train_accuracy = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        \n",
    "        inputs, label = data\n",
    "        inputs = inputs.float()\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        output = fnn_model1(inputs)\n",
    "        output = output.to(device)\n",
    "        loss1 = CEloss(output, label)\n",
    "        loss1.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        train_loss += loss1.item()\n",
    "        _, output = torch.max(output, 1)\n",
    "        output = output.cpu().detach().numpy()\n",
    "        label = label.cpu().detach().numpy()\n",
    "        label = np.argmax(label, axis = 1)\n",
    "        train_accuracy += accuracy_score(label, output)\n",
    "    \n",
    "    train_loss = train_loss/train_dataloader_len\n",
    "    train_accuracy = train_accuracy/train_dataloader_len\n",
    "    history_train.append((train_loss, train_accuracy))\n",
    "    \n",
    "    fnn_model1.eval()   \n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            \n",
    "            inputs, label = data\n",
    "            inputs = inputs.float()\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "            pred = fnn_model1(inputs)\n",
    "            pred = pred.to(device)\n",
    "            loss2 = CEloss(pred, label)\n",
    "\n",
    "            test_loss += loss2.item()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            label = label.cpu().detach().numpy()\n",
    "            label = np.argmax(label, axis = 1)\n",
    "            test_accuracy += accuracy_score(label, pred)\n",
    "            \n",
    "        test_loss = test_loss/test_dataloader_len\n",
    "        test_accuracy = test_accuracy/test_dataloader_len\n",
    "        history_test.append((test_loss, test_accuracy))\n",
    "    \n",
    "#     print(\"Epoch:\", (epoch+1))\n",
    "#     print(\"Train Loss:\", train_loss, \"\\tTrain Accuracy:\", train_accuracy)\n",
    "#     print(\"Test Loss:\", test_loss, \"\\tTest Accuracy:\", test_accuracy)\n",
    "#     print(\"=======================================================================================\")\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "\n",
    "print(\"Final test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151192df",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5230f01",
   "metadata": {},
   "source": [
    "#### PART A (Simple RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd73aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting the maximum review length to 20 by truncating longer reviews and padding shorter reviews with a null value 0 (for creating our dataset)\n",
    "new_data = []\n",
    "sent = []\n",
    "\n",
    "for i in range(len(df['text'])):\n",
    "    split_sent = df['text'].values[i].split(' ')\n",
    "    for word in split_sent[:20]:\n",
    "        sent.append(word)\n",
    "\n",
    "    if len(split_sent) < 20:\n",
    "        for i in range(20-len(split_sent)):\n",
    "            sent.append('0')\n",
    "    \n",
    "    new_data.append(sent)\n",
    "    sent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "952670a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_data = []\n",
    "sent = []\n",
    "\n",
    "for i in range(len(new_data)):\n",
    "    sent_part = new_data[i]\n",
    "    for word in sent_part:\n",
    "        try:\n",
    "            sent.append(word_2_vec[word])\n",
    "        except:\n",
    "            sent.append(np.zeros(300))\n",
    "    sent = np.array(sent)\n",
    "    rnn_data.append(sent)\n",
    "    sent = []\n",
    "rnn_data = np.array(rnn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f88f1c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 20, 300) (12000, 20, 300) (48000, 3) (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rnn_data, enc_data_label, test_size = 0.2, random_state=10)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "43526e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_dataset = Dataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_dataset = Dataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa3b52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(300, 20, 1, batch_first = True, nonlinearity='relu')\n",
    "        self.fc1 = nn.Linear(20, 3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "         \n",
    "        x, hn = self.rnn(x)\n",
    "        x = nn.functional.relu(self.fc1(x[:, -1, :]))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1d681a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = RNN().to(device)\n",
    "rnn_model = rnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c5e1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(rnn_model.parameters(), lr = 0.001)\n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec5acdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.36236702127659576\n",
      "Train accuracy: 0.40335494237588654\n",
      "Train accuracy: 0.5445617242907802\n",
      "Train accuracy: 0.5819758421985816\n",
      "Train accuracy: 0.5986743683510638\n",
      "Train accuracy: 0.6095135195035462\n",
      "Train accuracy: 0.6140431072695036\n",
      "Train accuracy: 0.6197154809397163\n",
      "Train accuracy: 0.6250692597517731\n",
      "Train accuracy: 0.6271678302304964\n",
      "Train accuracy: 0.6314619348404256\n",
      "Train accuracy: 0.6339206560283688\n",
      "Train accuracy: 0.6362062278368794\n",
      "Train accuracy: 0.6364624889184397\n",
      "Train accuracy: 0.6418162677304964\n",
      "Train accuracy: 0.6444966201241135\n",
      "Train accuracy: 0.6458887411347517\n",
      "Train accuracy: 0.6455216644503546\n",
      "Train accuracy: 0.6476617907801419\n",
      "Train accuracy: 0.6482989804964538\n",
      "Train accuracy: 0.6517619680851063\n",
      "Train accuracy: 0.6535211657801419\n",
      "Train accuracy: 0.6512840757978723\n",
      "Train accuracy: 0.6547816932624113\n",
      "Train accuracy: 0.6589857601950355\n",
      "Train accuracy: 0.6588403147163121\n",
      "Train accuracy: 0.6606202903368794\n",
      "Train accuracy: 0.6619708554964538\n",
      "Train accuracy: 0.6621647828014184\n",
      "Train accuracy: 0.660883477393617\n",
      "Train accuracy: 0.6633006427304964\n",
      "Train accuracy: 0.6654130651595744\n",
      "Train accuracy: 0.6676640070921985\n",
      "Train accuracy: 0.6701781360815603\n",
      "Train accuracy: 0.666105662677305\n",
      "Train accuracy: 0.6682527149822696\n",
      "Train accuracy: 0.6689660904255319\n",
      "Train accuracy: 0.6717226285460993\n",
      "Train accuracy: 0.671646442819149\n",
      "Train accuracy: 0.6734125664893617\n",
      "Final test accuracy: 0.6428687686011905\n"
     ]
    }
   ],
   "source": [
    "history_train = []\n",
    "history_test = []\n",
    "train_dataloader_len = len(train_dataloader)\n",
    "test_dataloader_len = len(test_dataloader)\n",
    "train_len = X_train.shape[0]\n",
    "test_len = X_test.shape[0]\n",
    "\n",
    "for epoch in range(40):  \n",
    "    rnn_model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    train_accuracy = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        \n",
    "        inputs, label = data\n",
    "        inputs = inputs.float()\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        output = rnn_model(inputs)\n",
    "        output = output.to(device)\n",
    "        loss1 = CEloss(output, label)\n",
    "        loss1.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        train_loss += loss1.item()\n",
    "        _, output = torch.max(output, 1)\n",
    "        output = output.cpu().detach().numpy()\n",
    "        label = label.cpu().detach().numpy()\n",
    "        label = np.argmax(label, axis = 1)\n",
    "        train_accuracy += accuracy_score(label, output)\n",
    "    \n",
    "    train_loss = train_loss/train_dataloader_len\n",
    "    train_accuracy = train_accuracy/train_dataloader_len\n",
    "    history_train.append((train_loss, train_accuracy))\n",
    "    \n",
    "    rnn_model.eval()   \n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            \n",
    "            inputs, label = data\n",
    "            inputs = inputs.float()\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "            pred = rnn_model(inputs)\n",
    "            pred = pred.to(device)\n",
    "            loss2 = CEloss(pred, label)\n",
    "\n",
    "            test_loss += loss2.item()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            label = label.cpu().detach().numpy()\n",
    "            label = np.argmax(label, axis = 1)\n",
    "            test_accuracy += accuracy_score(label, pred)\n",
    "            \n",
    "        test_loss = test_loss/test_dataloader_len\n",
    "        test_accuracy = test_accuracy/test_dataloader_len\n",
    "        history_test.append((test_loss, test_accuracy))\n",
    "    \n",
    "#     print(\"Epoch:\", (epoch+1))\n",
    "#     print(\"Train Loss:\", train_loss, \"\\tTrain Accuracy:\", train_accuracy)\n",
    "#     print(\"Test Loss:\", test_loss, \"\\tTest Accuracy:\", test_accuracy)\n",
    "#     print(\"=======================================================================================\")\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "\n",
    "print(\"Final test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad2985",
   "metadata": {},
   "source": [
    "##### FNN gives better test accuracy than Simple RNN. But the dataset (input) is different for Simple RNN and FNN. If the dataset would have been same, RNN would have given better test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f56135",
   "metadata": {},
   "source": [
    "#### PART B (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "05060f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(300, 20, 1, batch_first = True)\n",
    "        self.fc1 = nn.Linear(20, 3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "         \n",
    "        x, hn = self.gru(x)\n",
    "        x = nn.functional.relu(self.fc1(x[:, -1, :]))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eac09ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = GRU().to(device)\n",
    "gru_model = gru_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ebecd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(gru_model.parameters(), lr = 0.001)\n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b341e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.37563026374113473\n",
      "Train accuracy: 0.5224678634751773\n",
      "Train accuracy: 0.6130388408687943\n",
      "Train accuracy: 0.6416777482269503\n",
      "Train accuracy: 0.658521719858156\n",
      "Train accuracy: 0.6698526152482269\n",
      "Train accuracy: 0.6727199689716312\n",
      "Train accuracy: 0.6785931959219857\n",
      "Train accuracy: 0.6806155806737589\n",
      "Train accuracy: 0.6861979166666667\n",
      "Train accuracy: 0.6874307402482269\n",
      "Train accuracy: 0.6905959109042553\n",
      "Train accuracy: 0.6939827127659575\n",
      "Train accuracy: 0.6948276817375886\n",
      "Train accuracy: 0.6992741578014184\n",
      "Train accuracy: 0.6974734042553191\n",
      "Train accuracy: 0.7002091644503545\n",
      "Train accuracy: 0.7024670323581561\n",
      "Train accuracy: 0.7037552637411348\n",
      "Train accuracy: 0.7050227171985816\n",
      "Train accuracy: 0.707121287677305\n",
      "Train accuracy: 0.7081186281028369\n",
      "Train accuracy: 0.7086588541666667\n",
      "Train accuracy: 0.7124404366134752\n",
      "Train accuracy: 0.7141580784574468\n",
      "Train accuracy: 0.7138187056737588\n",
      "Train accuracy: 0.7138533355496455\n",
      "Train accuracy: 0.7167760970744681\n",
      "Train accuracy: 0.7173440270390071\n",
      "Train accuracy: 0.7165336879432624\n",
      "Train accuracy: 0.7182374778368795\n",
      "Train accuracy: 0.7183482934397163\n",
      "Train accuracy: 0.7213056848404256\n",
      "Train accuracy: 0.7243115580673758\n",
      "Train accuracy: 0.7245054853723404\n",
      "Train accuracy: 0.7245885970744681\n",
      "Train accuracy: 0.7251703789893617\n",
      "Train accuracy: 0.7284394392730497\n",
      "Train accuracy: 0.7272758754432624\n",
      "Train accuracy: 0.7272066156914894\n",
      "Final test accuracy: 0.6827450706845238\n"
     ]
    }
   ],
   "source": [
    "history_train = []\n",
    "history_test = []\n",
    "train_dataloader_len = len(train_dataloader)\n",
    "test_dataloader_len = len(test_dataloader)\n",
    "train_len = X_train.shape[0]\n",
    "test_len = X_test.shape[0]\n",
    "\n",
    "for epoch in range(40):  \n",
    "    gru_model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    train_accuracy = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        \n",
    "        inputs, label = data\n",
    "        inputs = inputs.float()\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        output = gru_model(inputs)\n",
    "        output = output.to(device)\n",
    "        loss1 = CEloss(output, label)\n",
    "        loss1.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        train_loss += loss1.item()\n",
    "        _, output = torch.max(output, 1)\n",
    "        output = output.cpu().detach().numpy()\n",
    "        label = label.cpu().detach().numpy()\n",
    "        label = np.argmax(label, axis = 1)\n",
    "        train_accuracy += accuracy_score(label, output)\n",
    "    \n",
    "    train_loss = train_loss/train_dataloader_len\n",
    "    train_accuracy = train_accuracy/train_dataloader_len\n",
    "    history_train.append((train_loss, train_accuracy))\n",
    "    \n",
    "    gru_model.eval()   \n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            \n",
    "            inputs, label = data\n",
    "            inputs = inputs.float()\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "            pred = gru_model(inputs)\n",
    "            pred = pred.to(device)\n",
    "            loss2 = CEloss(pred, label)\n",
    "\n",
    "            test_loss += loss2.item()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            label = label.cpu().detach().numpy()\n",
    "            label = np.argmax(label, axis = 1)\n",
    "            test_accuracy += accuracy_score(label, pred)\n",
    "            \n",
    "        test_loss = test_loss/test_dataloader_len\n",
    "        test_accuracy = test_accuracy/test_dataloader_len\n",
    "        history_test.append((test_loss, test_accuracy))\n",
    "    \n",
    "#     print(\"Epoch:\", (epoch+1))\n",
    "#     print(\"Train Loss:\", train_loss, \"\\tTrain Accuracy:\", train_accuracy)\n",
    "#     print(\"Test Loss:\", test_loss, \"\\tTest Accuracy:\", test_accuracy)\n",
    "#     print(\"=======================================================================================\")\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "print(\"Final test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069286c5",
   "metadata": {},
   "source": [
    "#### PART C (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7479b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(300, 20, 1, batch_first = True)\n",
    "        self.fc1 = nn.Linear(20, 3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "         \n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        x = nn.functional.relu(self.fc1(x[:, -1, :]))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ccac73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM().to(device)\n",
    "lstm_model = lstm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a589d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(lstm_model.parameters(), lr = 0.001)\n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7bd1b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.38286790780141844\n",
      "Train accuracy: 0.509537067819149\n",
      "Train accuracy: 0.609942929964539\n",
      "Train accuracy: 0.6386926529255319\n",
      "Train accuracy: 0.6527039007092198\n",
      "Train accuracy: 0.659747617464539\n",
      "Train accuracy: 0.6685436059397163\n",
      "Train accuracy: 0.6707876218971631\n",
      "Train accuracy: 0.6771179632092198\n",
      "Train accuracy: 0.67853086214539\n",
      "Train accuracy: 0.6827695589539008\n",
      "Train accuracy: 0.6838361591312057\n",
      "Train accuracy: 0.6894877548758864\n",
      "Train accuracy: 0.689591644503546\n",
      "Train accuracy: 0.6921057734929078\n",
      "Train accuracy: 0.6966007313829787\n",
      "Train accuracy: 0.6983530031028369\n",
      "Train accuracy: 0.6996343085106383\n",
      "Train accuracy: 0.7026817375886524\n",
      "Train accuracy: 0.7042539339539008\n",
      "Train accuracy: 0.7065949135638298\n",
      "Train accuracy: 0.7080562943262412\n",
      "Train accuracy: 0.7098362699468085\n",
      "Train accuracy: 0.7099193816489362\n",
      "Train accuracy: 0.7113322805851063\n",
      "Train accuracy: 0.7145528590425532\n",
      "Train accuracy: 0.7148021941489362\n",
      "Train accuracy: 0.7178149933510638\n",
      "Train accuracy: 0.7155155695921986\n",
      "Train accuracy: 0.7161943151595744\n",
      "Train accuracy: 0.7206200132978723\n",
      "Train accuracy: 0.7222614694148937\n",
      "Train accuracy: 0.7219775044326242\n",
      "Train accuracy: 0.7244847074468085\n",
      "Train accuracy: 0.7251011192375886\n",
      "Train accuracy: 0.7265971298758864\n",
      "Train accuracy: 0.7277122118794327\n",
      "Train accuracy: 0.7293051861702128\n",
      "Train accuracy: 0.7305726396276596\n",
      "Train accuracy: 0.7319093528368795\n",
      "Final test accuracy: 0.6812220982142857\n"
     ]
    }
   ],
   "source": [
    "history_train = []\n",
    "history_test = []\n",
    "train_dataloader_len = len(train_dataloader)\n",
    "test_dataloader_len = len(test_dataloader)\n",
    "train_len = X_train.shape[0]\n",
    "test_len = X_test.shape[0]\n",
    "\n",
    "for epoch in range(40): \n",
    "    lstm_model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    train_accuracy = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        \n",
    "        inputs, label = data\n",
    "        inputs = inputs.float()\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        output = lstm_model(inputs)\n",
    "        output = output.to(device)\n",
    "        loss1 = CEloss(output, label)\n",
    "        loss1.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        train_loss += loss1.item()\n",
    "        _, output = torch.max(output, 1)\n",
    "        output = output.cpu().detach().numpy()\n",
    "        label = label.cpu().detach().numpy()\n",
    "        label = np.argmax(label, axis = 1)\n",
    "        train_accuracy += accuracy_score(label, output)\n",
    "    \n",
    "    train_loss = train_loss/train_dataloader_len\n",
    "    train_accuracy = train_accuracy/train_dataloader_len\n",
    "    history_train.append((train_loss, train_accuracy))\n",
    "    \n",
    "    lstm_model.eval()   \n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            \n",
    "            inputs, label = data\n",
    "            inputs = inputs.float()\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "            pred = lstm_model(inputs)\n",
    "            pred = pred.to(device)\n",
    "            loss2 = CEloss(pred, label)\n",
    "\n",
    "            test_loss += loss2.item()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            label = label.cpu().detach().numpy()\n",
    "            label = np.argmax(label, axis = 1)\n",
    "            test_accuracy += accuracy_score(label, pred)\n",
    "            \n",
    "        test_loss = test_loss/test_dataloader_len\n",
    "        test_accuracy = test_accuracy/test_dataloader_len\n",
    "        history_test.append((test_loss, test_accuracy))\n",
    "    \n",
    "#     print(\"Epoch:\", (epoch+1))\n",
    "#     print(\"Train Loss:\", train_loss, \"\\tTrain Accuracy:\", train_accuracy)\n",
    "#     print(\"Test Loss:\", test_loss, \"\\tTest Accuracy:\", test_accuracy)\n",
    "#     print(\"=======================================================================================\")\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "\n",
    "print(\"Final test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d98bf",
   "metadata": {},
   "source": [
    "##### We can conclude that GRU and LSTM give better results than Simple RNN for our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78359b74",
   "metadata": {},
   "source": [
    "Reference: https://github.com/27rg5/Sentiment-Analysis-using-Deep-Learning/tree/master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
